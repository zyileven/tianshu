# 企业级 AI 数据预处理平台 - 支持 GPU 加速的多模态文档处理服务
#
# 构建方式:
#   docker build -t tianshu-backend:latest -f backend/Dockerfile .
#
# 运行方式:
#   docker run --gpus all -p 8000:8000 tianshu-backend:latest

# ============================================================================
# Stage 1: Base Image with CUDA Support
# ============================================================================
FROM nvidia/cuda:12.6.2-cudnn-runtime-ubuntu24.04 AS base

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH \
    PIP_CACHE_DIR=/root/.cache/pip

# 安装系统依赖
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.12 \
    python3.12-dev \
    python3-pip \
    python3.12-venv \
    git \
    wget \
    curl \
    libgomp1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgl1 \
    libgstreamer1.0-0 \
    ffmpeg \
    antiword \
    pandoc \
    && rm -rf /var/lib/apt/lists/*

# 安装 LibreOffice (固定大版本,确保构建可重现)
# Ubuntu 24.04 默认提供 LibreOffice 24.8.x
# 固定到 24.8.x 系列,避免大版本升级带来的不兼容
RUN apt-get update && \
    echo "Available LibreOffice versions:" && \
    apt-cache policy libreoffice | head -20 && \
    apt-get install -y --no-install-recommends \
    libreoffice \
    libreoffice-writer \
    libreoffice-calc \
    libreoffice-impress \
    && echo "Installed LibreOffice version:" && \
    libreoffice --version \
    && rm -rf /var/lib/apt/lists/*

# 创建符号链接，让 python3 指向 python3.12
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 \
    && update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1

# 升级 pip（使用国内镜像源，增加超时时间）
RUN --mount=type=cache,target=/root/.cache/pip \
    python3 -m pip install --upgrade pip setuptools wheel \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --ignore-installed \
    --default-timeout=300

# ============================================================================
# Stage 2: Dependencies Installation
# ============================================================================
FROM base AS dependencies

WORKDIR /tmp

# 复制 requirements.txt
COPY backend/requirements.txt /tmp/requirements.txt

# 分步安装依赖（解决 PyTorch + PaddlePaddle CUDA 冲突）
# 使用 BuildKit 缓存挂载，避免重复下载大文件
# Step 1: 安装 PaddlePaddle GPU 版本（~1.8GB，首次较慢，后续使用缓存）
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install paddlepaddle-gpu==3.2.0 \
    -i https://www.paddlepaddle.org.cn/packages/stable/cu126/ \
    --break-system-packages \
    --default-timeout=600 \
    --retries 5

# Step 2: 安装 PyTorch (CUDA 12.1, ~2GB, 包含 torchaudio for SenseVoice/FunASR)
# 使用 PyTorch 2.5.1 而不是 2.6.0，避免 weights_only=True 导致的模型加载问题
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 \
    --index-url https://download.pytorch.org/whl/cu121 \
    --break-system-packages \
    --default-timeout=600 \
    --retries 5

# Step 3: 预先安装 Python 3.12 关键依赖
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install "kiwisolver>=1.4.5" "Pillow>=11.0.0" \
    "numpy>=1.26.0,<2.0.0" "setuptools>=75.0.0" "lxml>=5.3.0" \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --default-timeout=300 \
    --retries 5

# Step 3.5: 安装 transformers 核心依赖（regex、huggingface-hub 等）
RUN --mount=type=cache,target=/root/.cache/pip \
    echo "Installing transformers dependencies..." && \
    pip install regex packaging filelock requests tqdm \
    "huggingface-hub>=0.23.2,<1.0" \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --default-timeout=300 \
    --retries 5

# Step 4: 安装核心包
# 分两步：先安装 mineru 的依赖，再安装 mineru 本身（避免依赖回溯）
RUN --mount=type=cache,target=/root/.cache/pip \
    echo "Installing MinerU dependencies first..." && \
    pip install doclayout-yolo ftfy dill rapidfuzz \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --default-timeout=300 \
    --retries 5

RUN --mount=type=cache,target=/root/.cache/pip \
    echo "Installing core packages with --no-deps..." && \
    pip install mineru[core] paddleocr[doc-parser] \
    transformers==4.46.3 tokenizers==0.20.3 \
    fastapi uvicorn litserve aiohttp \
    PyMuPDF Pillow img2pdf einops easydict addict loguru modelscope \
    albumentations minio markitdown \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --no-deps \
    --default-timeout=300 \
    --retries 5 || echo "⚠ Some packages skipped (will be resolved in next step)"

# Step 5: 安装 safetensors（PaddlePaddle 依赖）
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --break-system-packages \
    --default-timeout=300 \
    --retries 5 \
    https://paddle-whl.bj.bcebos.com/nightly/cu126/safetensors/safetensors-0.6.2.dev0-cp38-abi3-linux_x86_64.whl

# Step 6: 解析剩余依赖（使用 legacy resolver，避免回溯超时）
RUN --mount=type=cache,target=/root/.cache/pip \
    echo "Resolving remaining dependencies with legacy resolver..." && \
    pip install -r /tmp/requirements.txt \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --break-system-packages \
    --use-deprecated=legacy-resolver \
    --default-timeout=600 \
    --retries 5

# 验证安装（仅检查导入，不验证 CUDA，因为构建时无 GPU）
RUN python -c "import sys; print('Python:', sys.version)" && \
    python -c "import torch; print('✅ PyTorch:', torch.__version__)" && \
    python -c "import transformers; print('✅ Transformers:', transformers.__version__)" && \
    python -c "import funasr; print('✅ FunASR:', funasr.__version__)" && \
    echo "⚠️  Paddle CUDA 验证将在运行时进行（构建时无 GPU 访问）"

# ============================================================================
# Stage 3: Application
# ============================================================================
FROM dependencies AS application

# 创建应用目录
WORKDIR /app

# 复制后端代码
COPY backend/ /app/backend/
COPY pyproject.toml /app/

# 复制启动脚本
COPY scripts/docker-entrypoint.sh /usr/local/bin/docker-entrypoint.sh
COPY scripts/init-models.sh /usr/local/bin/init-models.sh
RUN chmod +x /usr/local/bin/docker-entrypoint.sh /usr/local/bin/init-models.sh

# 创建必要的目录
RUN mkdir -p /app/models /app/data /app/uploads /app/output /app/logs

# 设置工作目录为后端
WORKDIR /app/backend

# 暴露端口
# 8000: API Server
# 8001: LitServe Worker
# 8002: MCP Server
EXPOSE 8000 8001 8002

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 使用 entrypoint 脚本
ENTRYPOINT ["/usr/local/bin/docker-entrypoint.sh"]

# 默认启动 API Server
# 第一个参数是服务类型（api/worker/mcp），用于 entrypoint 判断
CMD ["api", "python", "api_server.py"]
