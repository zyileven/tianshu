"""
MinerU Tianshu - API Server
å¤©æ¢ API æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
æä¾› RESTful API æ¥å£ç”¨äºä»»åŠ¡æäº¤ã€æŸ¥è¯¢å’Œç®¡ç†
ä¼ä¸šçº§è®¤è¯æˆæƒ: JWT Token + API Key + SSO
"""

import json
import os
import re
import uuid
from datetime import datetime
from pathlib import Path
from typing import Optional
from urllib.parse import quote

import uvicorn
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Query, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from loguru import logger

# å¯¼å…¥è®¤è¯æ¨¡å—
from auth import (
    User,
    Permission,
    get_current_active_user,
    require_permission,
)
from auth.auth_db import AuthDB
from auth.routes import router as auth_router
from task_db import TaskDB

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="MinerU Tianshu API",
    description="å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° | æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç† | ä¼ä¸šçº§è®¤è¯æˆæƒ",
    version="2.0.0",
    # ä¸è®¾ç½® serversï¼Œè®© FastAPI è‡ªåŠ¨æ ¹æ®è¯·æ±‚çš„ Host ç”Ÿæˆ
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æ•°æ®åº“
# ç¡®ä¿ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ•°æ®åº“è·¯å¾„ï¼ˆä¸ Worker ä¿æŒä¸€è‡´ï¼‰
db_path_env = os.getenv("DATABASE_PATH")
if db_path_env:
    db_path = str(Path(db_path_env).resolve())
    logger.info(f"ğŸ“Š API Server using DATABASE_PATH: {db_path_env} -> {db_path}")
    db = TaskDB(db_path)
else:
    logger.warning("âš ï¸  DATABASE_PATH not set in API Server, using default")
    # ä½¿ç”¨ä¸ Worker ä¸€è‡´çš„é»˜è®¤è·¯å¾„
    db_path = "/app/data/db/mineru_tianshu.db"
    db = TaskDB(db_path)
auth_db = AuthDB()

# æ³¨å†Œè®¤è¯è·¯ç”±
app.include_router(auth_router)

# é…ç½®è¾“å‡ºç›®å½•ï¼ˆä½¿ç”¨å…±äº«ç›®å½•ï¼ŒDocker ç¯å¢ƒå¯è®¿é—®ï¼‰
OUTPUT_DIR = Path(os.getenv("OUTPUT_PATH", "/app/output"))
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


# æ³¨æ„ï¼šæ­¤å‡½æ•°å·²åºŸå¼ƒï¼ŒWorker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFS å¹¶æ›¿æ¢ URL
# ä¿ç•™æ­¤å‡½æ•°ä»…ç”¨äºå‘åå…¼å®¹ï¼ˆå¤„ç†æ—§ä»»åŠ¡æˆ– RustFS å¤±è´¥çš„æƒ…å†µï¼‰
def process_markdown_images_legacy(md_content: str, image_dir: Path, result_path: str):
    """
    ã€å·²åºŸå¼ƒã€‘å¤„ç† Markdown ä¸­çš„å›¾ç‰‡å¼•ç”¨

    Worker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFS å¹¶æ›¿æ¢ URLï¼Œæ­¤å‡½æ•°ä»…ç”¨äºå‘åå…¼å®¹ã€‚
    å¦‚æœæ£€æµ‹åˆ°å›¾ç‰‡è·¯å¾„ä¸æ˜¯ URLï¼Œåˆ™è½¬æ¢ä¸ºæœ¬åœ°é™æ€æ–‡ä»¶æœåŠ¡ URLã€‚

    Args:
        md_content: Markdown å†…å®¹
        image_dir: å›¾ç‰‡æ‰€åœ¨ç›®å½•
        result_path: ä»»åŠ¡ç»“æœè·¯å¾„

    Returns:
        å¤„ç†åçš„ Markdown å†…å®¹
    """
    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å« RustFS URL
    if "http://" in md_content or "https://" in md_content:
        logger.debug("âœ… Markdown already contains URLs (RustFS uploaded)")
        return md_content

    # å¦‚æœæ²¡æœ‰å›¾ç‰‡ç›®å½•ï¼Œç›´æ¥è¿”å›
    if not image_dir.exists():
        logger.debug("â„¹ï¸  No images directory, skipping processing")
        return md_content

    # å…¼å®¹æ¨¡å¼ï¼šè½¬æ¢ç›¸å¯¹è·¯å¾„ä¸ºæœ¬åœ° URL
    logger.warning("âš ï¸  Images not uploaded to RustFS, using local URLs (legacy mode)")

    def replace_image_path(match):
        """æ›¿æ¢å›¾ç‰‡è·¯å¾„ä¸ºæœ¬åœ° URL"""
        full_match = match.group(0)
        # æå–å›¾ç‰‡è·¯å¾„ï¼ˆMarkdown æˆ– HTMLï¼‰
        if "![" in full_match:
            # Markdown: ![alt](path)
            image_path = match.group(2)
            alt_text = match.group(1)
        else:
            # HTML: <img src="path">
            image_path = match.group(2)
            alt_text = "Image"

        # å¦‚æœå·²ç»æ˜¯ URLï¼Œè·³è¿‡
        if image_path.startswith("http"):
            return full_match

        # ç”Ÿæˆæœ¬åœ°é™æ€æ–‡ä»¶ URL
        try:
            image_filename = Path(image_path).name
            output_dir_str = str(OUTPUT_DIR).replace("\\", "/")
            result_path_str = result_path.replace("\\", "/")

            if result_path_str.startswith(output_dir_str):
                relative_path = result_path_str[len(output_dir_str) :].lstrip("/")
                encoded_relative_path = quote(relative_path, safe="/")
                encoded_filename = quote(image_filename, safe="/")
                static_url = f"/api/v1/files/output/{encoded_relative_path}/images/{encoded_filename}"

                # è¿”å›æ›¿æ¢åçš„å†…å®¹
                if "![" in full_match:
                    return f"![{alt_text}]({static_url})"
                else:
                    return full_match.replace(image_path, static_url)
        except Exception as e:
            logger.error(f"âŒ Failed to generate local URL: {e}")

        return full_match

    try:
        # åŒ¹é… Markdown å’Œ HTML å›¾ç‰‡
        md_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"
        html_pattern = r'<img\s+([^>]*\s+)?src="([^"]+)"([^>]*)>'

        new_content = re.sub(md_pattern, replace_image_path, md_content)
        new_content = re.sub(html_pattern, replace_image_path, new_content)
        return new_content
    except Exception as e:
        logger.error(f"âŒ Failed to process images: {e}")
        return md_content


@app.get("/", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def root():
    """APIæ ¹è·¯å¾„"""
    return {
        "service": "MinerU Tianshu",
        "version": "1.0.0",
        "description": "å¤©æ¢ - ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å°",
        "features": "æ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†",
        "docs": "/docs",
    }


@app.post("/api/v1/tasks/submit", tags=["ä»»åŠ¡ç®¡ç†"])
async def submit_task(
    file: UploadFile = File(..., description="æ–‡ä»¶: PDF/å›¾ç‰‡/Office/HTML/éŸ³é¢‘/è§†é¢‘ç­‰å¤šç§æ ¼å¼"),
    backend: str = Form(
        "auto",
        description="å¤„ç†åç«¯: auto (è‡ªåŠ¨é€‰æ‹©) | pipeline/paddleocr-vl (æ–‡æ¡£) | sensevoice (éŸ³é¢‘) | video (è§†é¢‘) | fasta/genbank (ä¸“ä¸šæ ¼å¼)",
    ),
    lang: str = Form("auto", description="è¯­è¨€: auto/ch/en/korean/japanç­‰"),
    method: str = Form("auto", description="è§£ææ–¹æ³•: auto/txt/ocr"),
    formula_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«"),
    table_enable: bool = Form(True, description="æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«"),
    priority: int = Form(0, description="ä¼˜å…ˆçº§ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆ"),
    # è§†é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    keep_audio: bool = Form(False, description="è§†é¢‘å¤„ç†æ—¶æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘æ–‡ä»¶"),
    enable_keyframe_ocr: bool = Form(False, description="æ˜¯å¦å¯ç”¨è§†é¢‘å…³é”®å¸§OCRè¯†åˆ«ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼‰"),
    ocr_backend: str = Form("paddleocr-vl", description="å…³é”®å¸§OCRå¼•æ“: paddleocr-vl"),
    keep_keyframes: bool = Form(False, description="æ˜¯å¦ä¿ç•™æå–çš„å…³é”®å¸§å›¾åƒ"),
    # éŸ³é¢‘å¤„ç†ä¸“ç”¨å‚æ•°
    enable_speaker_diarization: bool = Form(
        False, description="æ˜¯å¦å¯ç”¨è¯´è¯äººåˆ†ç¦»ï¼ˆéŸ³é¢‘å¤šè¯´è¯äººè¯†åˆ«ï¼Œéœ€è¦é¢å¤–ä¸‹è½½ Paraformer æ¨¡å‹ï¼‰"
    ),
    # æ°´å°å»é™¤ä¸“ç”¨å‚æ•°
    remove_watermark: bool = Form(False, description="æ˜¯å¦å¯ç”¨æ°´å°å»é™¤ï¼ˆæ”¯æŒ PDF/å›¾ç‰‡ï¼‰"),
    watermark_conf_threshold: float = Form(0.35, description="æ°´å°æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œæ¨è 0.35ï¼‰"),
    watermark_dilation: int = Form(10, description="æ°´å°æ©ç è†¨èƒ€å¤§å°ï¼ˆåƒç´ ï¼Œæ¨è 10ï¼‰"),
    # å¼ºåˆ¶ MinerU å¤„ç†å‚æ•°
    force_mineru: bool = Form(
        False, description="å¼ºåˆ¶ä½¿ç”¨ MinerU å¤„ç†ï¼ˆå°† Office ç­‰æ–‡ä»¶è½¬ä¸º PDFï¼Œä»¥æå–æ–‡æ¡£å†…çš„å›¾ç‰‡ï¼‰"
    ),
    # è®¤è¯ä¾èµ–
    current_user: User = Depends(require_permission(Permission.TASK_SUBMIT)),
):
    """
    æäº¤æ–‡æ¡£è§£æä»»åŠ¡

    éœ€è¦è®¤è¯å’Œ TASK_SUBMIT æƒé™ã€‚
    ç«‹å³è¿”å› task_idï¼Œä»»åŠ¡åœ¨åå°å¼‚æ­¥å¤„ç†ã€‚
    """
    try:
        # åˆ›å»ºå…±äº«çš„ä¸Šä¼ ç›®å½•ï¼ˆBackend å’Œ Worker éƒ½èƒ½è®¿é—®ï¼‰
        upload_dir = Path("/app/uploads")
        upload_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆé¿å…å†²çªï¼‰
        unique_filename = f"{uuid.uuid4().hex}_{file.filename}"
        temp_file_path = upload_dir / unique_filename

        # æµå¼å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜ï¼Œé¿å…é«˜å†…å­˜ä½¿ç”¨
        with open(temp_file_path, "wb") as temp_file:
            while True:
                chunk = await file.read(1 << 23)  # 8MB chunks
                if not chunk:
                    break
                temp_file.write(chunk)

        # æ„å»ºå¤„ç†é€‰é¡¹
        options = {
            "lang": lang,
            "method": method,
            "formula_enable": formula_enable,
            "table_enable": table_enable,
            # è§†é¢‘å¤„ç†å‚æ•°
            "keep_audio": keep_audio,
            "enable_keyframe_ocr": enable_keyframe_ocr,
            "ocr_backend": ocr_backend,
            "keep_keyframes": keep_keyframes,
            # éŸ³é¢‘å¤„ç†å‚æ•°
            "enable_speaker_diarization": enable_speaker_diarization,
            # æ°´å°å»é™¤å‚æ•°
            "remove_watermark": remove_watermark,
            "watermark_conf_threshold": watermark_conf_threshold,
            "watermark_dilation": watermark_dilation,
            # å¼ºåˆ¶ MinerU å¤„ç†å‚æ•°
            "force_mineru": force_mineru,
        }

        # åˆ›å»ºä»»åŠ¡ï¼ˆPDF æ‹†åˆ†é€»è¾‘ç”± Worker å¤„ç†ï¼‰
        task_id = db.create_task(
            file_name=file.filename,
            file_path=str(temp_file_path),
            backend=backend,
            options=options,
            priority=priority,
            user_id=current_user.user_id,
        )

        logger.info(f"âœ… Task submitted: {task_id} - {file.filename}")
        logger.info(f"   User: {current_user.username} ({current_user.role.value})")
        logger.info(f"   Backend: {backend}")
        logger.info(f"   Priority: {priority}")

        return {
            "success": True,
            "task_id": task_id,
            "status": "pending",
            "message": "Task submitted successfully",
            "file_name": file.filename,
            "user_id": current_user.user_id,
            "created_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"âŒ Failed to submit task: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def get_task_status(
    task_id: str,
    upload_images: bool = Query(False, description="ã€å·²åºŸå¼ƒã€‘å›¾ç‰‡å·²è‡ªåŠ¨ä¸Šä¼ åˆ° RustFSï¼Œæ­¤å‚æ•°ä¿ç•™ä»…ç”¨äºå‘åå…¼å®¹"),
    format: str = Query("markdown", description="è¿”å›æ ¼å¼: markdown(é»˜è®¤)/json/both"),
    current_user: User = Depends(get_current_active_user),
):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œè¯¦æƒ…

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡ã€‚
    å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œä¼šè‡ªåŠ¨è¿”å›è§£æåçš„å†…å®¹ï¼ˆdata å­—æ®µï¼‰
    - format=markdown: åªè¿”å› Markdown å†…å®¹ï¼ˆé»˜è®¤ï¼‰
    - format=json: åªè¿”å› JSON ç»“æ„åŒ–æ•°æ®ï¼ˆMinerU å’Œ PaddleOCR-VL æ”¯æŒï¼‰
    - format=both: åŒæ—¶è¿”å› Markdown å’Œ JSON
    å¯é€‰æ‹©æ˜¯å¦ä¸Šä¼ å›¾ç‰‡åˆ° MinIO å¹¶æ›¿æ¢ä¸º URL
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_VIEW_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only view your own tasks")

    response = {
        "success": True,
        "task_id": task_id,
        "status": task["status"],
        "file_name": task["file_name"],
        "backend": task["backend"],
        "priority": task["priority"],
        "error_message": task["error_message"],
        "created_at": task["created_at"],
        "started_at": task["started_at"],
        "completed_at": task["completed_at"],
        "worker_id": task["worker_id"],
        "retry_count": task["retry_count"],
        "user_id": task.get("user_id"),
    }

    # å¦‚æœæ˜¯ä¸»ä»»åŠ¡,æ·»åŠ å­ä»»åŠ¡è¿›åº¦ä¿¡æ¯
    if task.get("is_parent"):
        child_count = task.get("child_count", 0)
        child_completed = task.get("child_completed", 0)

        response["is_parent"] = True
        response["subtask_progress"] = {
            "total": child_count,
            "completed": child_completed,
            "percentage": round(child_completed / child_count * 100, 1) if child_count > 0 else 0,
        }

        # å¯é€‰: è¿”å›æ‰€æœ‰å­ä»»åŠ¡çŠ¶æ€
        try:
            children = db.get_child_tasks(task_id)
            response["subtasks"] = [
                {
                    "task_id": child["task_id"],
                    "status": child["status"],
                    "chunk_info": json.loads(child.get("options", "{}")).get("chunk_info"),
                    "error_message": child.get("error_message"),
                }
                for child in children
            ]
            logger.info(f"âœ… Parent task status: {task['status']} - Progress: {child_completed}/{child_count} subtasks")
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to load subtasks: {e}")

    else:
        logger.info(f"âœ… Task status: {task['status']} - (result_path: {task.get('result_path')})")

    # å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œå°è¯•è¿”å›è§£æå†…å®¹
    if task["status"] == "completed":
        if not task["result_path"]:
            # ç»“æœæ–‡ä»¶å·²è¢«æ¸…ç†
            response["data"] = None
            response["message"] = "Task completed but result files have been cleaned up (older than retention period)"
            return response

        result_dir = Path(task["result_path"])
        logger.info(f"ğŸ“‚ Checking result directory: {result_dir}")

        if result_dir.exists():
            logger.info("âœ… Result directory exists")
            # é€’å½’æŸ¥æ‰¾ Markdown æ–‡ä»¶ï¼ˆMinerU è¾“å‡ºç»“æ„ï¼štask_id/filename/auto/*.mdï¼‰
            md_files = list(result_dir.rglob("*.md"))
            # é€’å½’æŸ¥æ‰¾ JSON æ–‡ä»¶
            # MinerU è¾“å‡ºæ ¼å¼: {filename}_content_list.json (ä¸»è¦çš„ç»“æ„åŒ–å†…å®¹)
            # ä¹Ÿæ”¯æŒå…¶ä»–å¼•æ“çš„: content.json, result.json
            json_files = [
                f
                for f in result_dir.rglob("*.json")
                if not f.parent.name.startswith("page_")
                and (f.name in ["content.json", "result.json"] or "_content_list.json" in f.name)
            ]
            logger.info(f"ğŸ“„ Found {len(md_files)} markdown files and {len(json_files)} json files")

            if md_files:
                try:
                    # åˆå§‹åŒ– data å­—æ®µ
                    response["data"] = {}

                    # æ ‡è®° JSON æ˜¯å¦å¯ç”¨
                    response["data"]["json_available"] = len(json_files) > 0

                    # æ ¹æ® format å‚æ•°å†³å®šè¿”å›å†…å®¹
                    if format in ["markdown", "both"]:
                        # é€‰æ‹©ä¸» Markdown æ–‡ä»¶ï¼ˆä¼˜å…ˆ result.mdï¼‰
                        md_file = None
                        for f in md_files:
                            if f.name == "result.md":
                                md_file = f
                                break
                        if not md_file:
                            md_file = md_files[0]

                        # æŸ¥æ‰¾å›¾ç‰‡ç›®å½•ï¼ˆWorker å·²è§„èŒƒåŒ–ä¸º images/ï¼‰
                        image_dir = md_file.parent / "images"

                        # è¯»å– Markdown å†…å®¹ï¼ˆWorker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFSï¼‰
                        logger.info(f"ğŸ“– Reading markdown file: {md_file}")
                        with open(md_file, "r", encoding="utf-8") as f:
                            md_content = f.read()

                        logger.info(f"âœ… Markdown content loaded, length: {len(md_content)} characters")

                        # Worker å·²è‡ªåŠ¨ä¸Šä¼ å›¾ç‰‡åˆ° RustFS å¹¶æ›¿æ¢ URL
                        # ä»…åœ¨å…¼å®¹æ¨¡å¼ä¸‹å¤„ç†ï¼ˆæ—§ä»»åŠ¡æˆ– RustFS å¤±è´¥ï¼‰
                        if image_dir.exists() and ("http://" not in md_content and "https://" not in md_content):
                            logger.warning("âš ï¸  Images not uploaded to RustFS, using legacy mode")
                            md_content = process_markdown_images_legacy(md_content, image_dir, task["result_path"])
                        else:
                            logger.debug("âœ… Images already processed by Worker (RustFS URLs)")

                        # æ·»åŠ  Markdown ç›¸å…³å­—æ®µ
                        response["data"]["markdown_file"] = md_file.name
                        response["data"]["content"] = md_content
                        response["data"]["has_images"] = image_dir.exists()

                    # å¦‚æœç”¨æˆ·è¯·æ±‚ JSON æ ¼å¼
                    if format in ["json", "both"] and json_files:
                        import json as json_lib

                        json_file = json_files[0]
                        logger.info(f"ğŸ“– Reading JSON file: {json_file}")
                        try:
                            with open(json_file, "r", encoding="utf-8") as f:
                                json_content = json_lib.load(f)
                            response["data"]["json_file"] = json_file.name
                            response["data"]["json_content"] = json_content
                            logger.info("âœ… JSON content loaded successfully")
                        except Exception as json_e:
                            logger.warning(f"âš ï¸  Failed to load JSON: {json_e}")
                    elif format == "json" and not json_files:
                        # ç”¨æˆ·è¯·æ±‚ JSON ä½†æ²¡æœ‰ JSON æ–‡ä»¶
                        logger.warning("âš ï¸  JSON format requested but no JSON file available")
                        response["data"]["message"] = "JSON format not available for this backend"

                    # å¦‚æœæ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹ï¼Œæ·»åŠ æç¤º
                    if not response["data"]:
                        response["data"] = None
                        logger.warning(f"âš ï¸  No data returned for format: {format}")
                    else:
                        logger.info(f"âœ… Response data field added successfully (format={format})")

                except Exception as e:
                    logger.error(f"âŒ Failed to read content: {e}")
                    logger.exception(e)
                    # è¯»å–å¤±è´¥ä¸å½±å“çŠ¶æ€æŸ¥è¯¢ï¼Œåªæ˜¯ä¸è¿”å› data
                    response["data"] = None
            else:
                logger.warning(f"âš ï¸  No markdown files found in {result_dir}")
        else:
            logger.error(f"âŒ Result directory does not exist: {result_dir}")
    else:
        logger.info(f"â„¹ï¸  Task status is {task['status']}, skipping content loading")

    return response


@app.delete("/api/v1/tasks/{task_id}", tags=["ä»»åŠ¡ç®¡ç†"])
async def cancel_task(task_id: str, current_user: User = Depends(get_current_active_user)):
    """
    å–æ¶ˆä»»åŠ¡ï¼ˆä»…é™ pending çŠ¶æ€ï¼‰

    éœ€è¦è®¤è¯ã€‚ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡ã€‚
    """
    task = db.get_task(task_id)

    if not task:
        raise HTTPException(status_code=404, detail="Task not found")

    # æƒé™æ£€æŸ¥: ç”¨æˆ·åªèƒ½å–æ¶ˆè‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜å¯ä»¥å–æ¶ˆä»»ä½•ä»»åŠ¡
    if not current_user.has_permission(Permission.TASK_DELETE_ALL):
        if task.get("user_id") != current_user.user_id:
            raise HTTPException(status_code=403, detail="Permission denied: You can only cancel your own tasks")

    if task["status"] == "pending":
        db.update_task_status(task_id, "cancelled")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        file_path = Path(task["file_path"])
        if file_path.exists():
            file_path.unlink()

        logger.info(f"â¹ï¸  Task cancelled: {task_id} by user {current_user.username}")
        return {"success": True, "message": "Task cancelled successfully"}
    else:
        raise HTTPException(status_code=400, detail=f"Cannot cancel task in {task['status']} status")


@app.get("/api/v1/queue/stats", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def get_queue_stats(current_user: User = Depends(require_permission(Permission.QUEUE_VIEW))):
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯

    éœ€è¦è®¤è¯å’Œ QUEUE_VIEW æƒé™ã€‚
    """
    stats = db.get_queue_stats()

    return {
        "success": True,
        "stats": stats,
        "total": sum(stats.values()),
        "timestamp": datetime.now().isoformat(),
        "user": current_user.username,
    }


@app.get("/api/v1/queue/tasks", tags=["é˜Ÿåˆ—ç®¡ç†"])
async def list_tasks(
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€: pending/processing/completed/failed"),
    limit: int = Query(100, description="è¿”å›æ•°é‡é™åˆ¶", le=1000),
    current_user: User = Depends(get_current_active_user),
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨

    éœ€è¦è®¤è¯ã€‚æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡ï¼Œç®¡ç†å‘˜/ç»ç†å¯ä»¥çœ‹åˆ°æ‰€æœ‰ä»»åŠ¡ã€‚
    """
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    can_view_all = current_user.has_permission(Permission.TASK_VIEW_ALL)

    if can_view_all:
        # ç®¡ç†å‘˜/ç»ç†æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
        if status:
            tasks = db.get_tasks_by_status(status, limit)
        else:
            with db.get_cursor() as cursor:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (limit,),
                )
                tasks = [dict(row) for row in cursor.fetchall()]
    else:
        # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡
        with db.get_cursor() as cursor:
            if status:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ? AND status = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, status, limit),
                )
            else:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    WHERE user_id = ?
                    ORDER BY created_at DESC
                    LIMIT ?
                """,
                    (current_user.user_id, limit),
                )
            tasks = [dict(row) for row in cursor.fetchall()]

    return {"success": True, "count": len(tasks), "tasks": tasks, "can_view_all": can_view_all}


@app.post("/api/v1/admin/cleanup", tags=["ç³»ç»Ÿç®¡ç†"])
async def cleanup_old_tasks(
    days: int = Query(7, description="æ¸…ç†Nå¤©å‰çš„ä»»åŠ¡"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    æ¸…ç†æ—§ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰

    åŒæ—¶åˆ é™¤ä»»åŠ¡çš„æ‰€æœ‰ç›¸å…³æ–‡ä»¶å’Œæ•°æ®åº“è®°å½•ï¼š
    - ä¸Šä¼ çš„åŸå§‹æ–‡ä»¶
    - ç»“æœæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬ç”Ÿæˆçš„æ–‡ä»¶å’Œæ‰€æœ‰ä¸­é—´æ–‡ä»¶ï¼‰
    - æ•°æ®åº“è®°å½•

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    deleted_count = db.cleanup_old_task_records(days)

    logger.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks (files and records) by {current_user.username}")

    return {
        "success": True,
        "deleted_count": deleted_count,
        "message": f"Cleaned up {deleted_count} tasks older than {days} days (files and records deleted)",
    }


@app.post("/api/v1/admin/reset-stale", tags=["ç³»ç»Ÿç®¡ç†"])
async def reset_stale_tasks(
    timeout_minutes: int = Query(60, description="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"),
    current_user: User = Depends(require_permission(Permission.QUEUE_MANAGE)),
):
    """
    é‡ç½®è¶…æ—¶çš„ processing ä»»åŠ¡ï¼ˆç®¡ç†æ¥å£ï¼‰

    éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚
    """
    reset_count = db.reset_stale_tasks(timeout_minutes)

    logger.info(f"ğŸ”„ Reset {reset_count} stale tasks by {current_user.username}")

    return {
        "success": True,
        "reset_count": reset_count,
        "message": f"Reset tasks processing for more than {timeout_minutes} minutes",
    }


@app.get("/api/v1/engines", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def list_engines():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“

    æ— éœ€è®¤è¯ã€‚è¿”å›ç³»ç»Ÿä¸­æ‰€æœ‰å¯ç”¨çš„å¤„ç†å¼•æ“ä¿¡æ¯ã€‚
    """
    engines = {
        "document": [
            {
                "name": "pipeline",
                "display_name": "MinerU Pipeline",
                "description": "é»˜è®¤çš„ PDF/å›¾ç‰‡è§£æå¼•æ“ï¼Œæ”¯æŒå…¬å¼ã€è¡¨æ ¼ç­‰å¤æ‚ç»“æ„",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            },
        ],
        "ocr": [],
        "audio": [],
        "video": [],
        "format": [],
        "office": [
            {
                "name": "markitdown",
                "display_name": "MarkItDown",
                "description": "Office æ–‡æ¡£å’Œæ–‡æœ¬æ–‡ä»¶è½¬æ¢å¼•æ“",
                "supported_formats": [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt", ".html", ".txt", ".csv"],
            },
        ],
    }

    # åŠ¨æ€æ£€æµ‹å¯ç”¨å¼•æ“
    import importlib.util

    if importlib.util.find_spec("paddleocr_vl") is not None:
        engines["ocr"].append(
            {
                "name": "paddleocr_vl",
                "display_name": "PaddleOCR-VL",
                "description": "PaddlePaddle è§†è§‰è¯­è¨€ OCR å¼•æ“",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("paddleocr_vl_vllm") is not None:
        engines["ocr"].append(
            {
                "name": "paddleocr-vl-vllm",
                "display_name": "PaddleOCR-VL-VLLM",
                "description": "åŸºäº vLLM çš„é«˜æ€§èƒ½ PaddleOCR å¼•æ“",
                "supported_formats": [".pdf", ".png", ".jpg", ".jpeg"],
            }
        )

    if importlib.util.find_spec("audio_engines") is not None:
        engines["audio"].append(
            {
                "name": "sensevoice",
                "display_name": "SenseVoice",
                "description": "è¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œæ”¯æŒå¤šè¯­è¨€è‡ªåŠ¨æ£€æµ‹",
                "supported_formats": [".wav", ".mp3", ".flac", ".m4a", ".ogg"],
            }
        )

    if importlib.util.find_spec("video_engines") is not None:
        engines["video"].append(
            {
                "name": "video",
                "display_name": "Video Processing",
                "description": "è§†é¢‘å¤„ç†å¼•æ“ï¼Œæ”¯æŒå…³é”®å¸§æå–å’ŒéŸ³é¢‘è½¬å½•",
                "supported_formats": [".mp4", ".avi", ".mkv", ".mov", ".flv", ".wmv"],
            }
        )

    # ä¸“ä¸šæ ¼å¼å¼•æ“
    try:
        from format_engines import FormatEngineRegistry

        for engine_info in FormatEngineRegistry.list_engines():
            engines["format"].append(
                {
                    "name": engine_info["name"],
                    "display_name": engine_info["name"].upper(),
                    "description": engine_info["description"],
                    "supported_formats": engine_info["extensions"],
                }
            )
    except ImportError:
        pass

    return {
        "success": True,
        "engines": engines,
        "timestamp": datetime.now().isoformat(),
    }


@app.get("/api/v1/health", tags=["ç³»ç»Ÿä¿¡æ¯"])
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        stats = db.get_queue_stats()

        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": "connected",
            "queue_stats": stats,
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(status_code=503, content={"status": "unhealthy", "error": str(e)})


# ============================================================================
# è‡ªå®šä¹‰æ–‡ä»¶æœåŠ¡ï¼ˆæ”¯æŒ URL ç¼–ç çš„ä¸­æ–‡è·¯å¾„ï¼‰
# ============================================================================
from urllib.parse import unquote


@app.get("/v1/files/output/{file_path:path}", tags=["æ–‡ä»¶æœåŠ¡"])
async def serve_output_file(file_path: str):
    """
    æä¾›è¾“å‡ºæ–‡ä»¶çš„è®¿é—®æœåŠ¡

    æ”¯æŒ URL ç¼–ç çš„ä¸­æ–‡è·¯å¾„
    æ³¨æ„ï¼šNginx ä»£ç†ä¼šå»æ‰ /api/ å‰ç¼€ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦ /api/
    """
    try:
        logger.debug(f"ğŸ“¥ Received file request: {file_path}")
        # URL è§£ç 
        decoded_path = unquote(file_path)
        logger.debug(f"ğŸ“ Decoded path: {decoded_path}")
        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = OUTPUT_DIR / decoded_path
        logger.debug(f"ğŸ“‚ Full path: {full_path}")

        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„åœ¨ OUTPUT_DIR å†…
        try:
            full_path = full_path.resolve()
            OUTPUT_DIR.resolve()
            if not str(full_path).startswith(str(OUTPUT_DIR.resolve())):
                raise HTTPException(status_code=403, detail="Access denied")
        except Exception:
            raise HTTPException(status_code=403, detail="Invalid path")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not full_path.exists():
            logger.warning(f"âš ï¸  File not found: {full_path}")
            raise HTTPException(status_code=404, detail="File not found")

        if not full_path.is_file():
            raise HTTPException(status_code=404, detail="Not a file")

        # è¿”å›æ–‡ä»¶
        return FileResponse(path=str(full_path), media_type="application/octet-stream", filename=full_path.name)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Error serving file: {e}")
        raise HTTPException(status_code=500, detail=str(e))


logger.info(f"ğŸ“ File service mounted: /v1/files/output -> {OUTPUT_DIR}")
logger.info("   Frontend can access images via: /api/v1/files/output/{task_id}/images/xxx.jpg (Nginx will strip /api/)")

if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è¯»å–ç«¯å£ï¼Œé»˜è®¤ä¸º8000
    api_port = int(os.getenv("API_PORT", "8000"))

    logger.info("ğŸš€ Starting MinerU Tianshu API Server...")
    logger.info(f"ğŸ“– API Documentation: http://localhost:{api_port}/docs")

    uvicorn.run(app, host="0.0.0.0", port=api_port, log_level="info")
