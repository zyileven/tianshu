#!/usr/bin/env python3
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬ - ä¸º CPU ç¦»çº¿éƒ¨ç½²å‡†å¤‡æ‰€æœ‰å¿…éœ€æ¨¡å‹

åŠŸèƒ½:
1. ä¸‹è½½ MinerU æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
2. è§¦å‘ PaddleOCR æ¨¡å‹è‡ªåŠ¨ä¸‹è½½
3. ä¸‹è½½ SenseVoice éŸ³é¢‘è¯†åˆ«æ¨¡å‹
4. ä¸‹è½½ Paraformer è¯´è¯äººåˆ†ç¦»æ¨¡å‹
5. ä¸‹è½½ YOLO11 æ°´å°æ£€æµ‹æ¨¡å‹
6. ä¸‹è½½ LaMa æ°´å°ä¿®å¤æ¨¡å‹
7. æ¨¡å‹éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
8. ç”Ÿæˆæ¨¡å‹æ¸…å• manifest.json

ç”¨æ³•:
    python download_models.py --output ./models-offline
    python download_models.py --output ./models-offline --models mineru,sensevoice
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")

# æ¨¡å‹é…ç½®
MODELS = {
    "mineru": {
        "name": "MinerU PDF-Extract-Kit",
        "repo_id": "opendatalab/PDF-Extract-Kit-1.0",
        "source": "huggingface",
        "target_dir": "huggingface/hub/",
        "description": "PDF OCR and layout analysis models",
        "required": True
    },
    "paddleocr": {
        "name": "PaddleOCR Multi-language Models",
        "auto_download": True,
        "target_dir": ".paddleocr/models/",
        "description": "Will be downloaded automatically on first run (~2GB)",
        "required": False
    },
    "sensevoice": {
        "name": "SenseVoice Audio Recognition",
        "model_id": "iic/SenseVoiceSmall",
        "source": "modelscope",
        "target_dir": "sensevoice/",
        "description": "Multi-language speech recognition model",
        "required": True
    },
    "paraformer": {
        "name": "Paraformer Speaker Diarization",
        "model_id": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "source": "modelscope",
        "target_dir": "paraformer/",
        "description": "Speaker diarization and VAD model",
        "required": False
    },
    "yolo11": {
        "name": "YOLO11x Watermark Detection",
        "repo_id": "corzent/yolo11x_watermark_detection",
        "filename": "best.pt",
        "source": "huggingface",
        "target_dir": "watermark_models/",
        "description": "Watermark detection model for document processing",
        "required": False
    },
    "lama": {
        "name": "LaMa Watermark Inpainting",
        "auto_download": True,
        "description": "Will be downloaded by simple_lama_inpainting on first use",
        "required": False
    }
}


def download_from_huggingface(repo_id, target_dir, filename=None):
    """ä» HuggingFace ä¸‹è½½æ¨¡å‹"""
    try:
        from huggingface_hub import snapshot_download, hf_hub_download

        # é…ç½®é•œåƒï¼ˆå›½å†…åŠ é€Ÿï¼‰
        hf_endpoint = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
        os.environ.setdefault("HF_ENDPOINT", hf_endpoint)

        if filename:
            # ä¸‹è½½å•ä¸ªæ–‡ä»¶
            logger.info(f"   Downloading file: {filename}")
            path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                cache_dir=str(target_dir),
                resume_download=True
            )
        else:
            # ä¸‹è½½æ•´ä¸ªä»“åº“
            logger.info(f"   Downloading repository: {repo_id}")
            path = snapshot_download(
                repo_id=repo_id,
                cache_dir=str(target_dir),
                resume_download=True
            )

        return path

    except ImportError:
        logger.error("   âŒ huggingface_hub not installed. Install: pip install huggingface-hub")
        return None
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None


def download_from_modelscope(model_id, target_dir):
    """ä» ModelScope ä¸‹è½½æ¨¡å‹"""
    try:
        from modelscope import snapshot_download

        logger.info(f"   Downloading from ModelScope: {model_id}")
        path = snapshot_download(
            model_id,
            cache_dir=str(target_dir),
            revision="master"
        )

        return path

    except ImportError:
        logger.error("   âŒ modelscope not installed. Install: pip install modelscope")
        return None
    except Exception as e:
        logger.error(f"   âŒ Download failed: {e}")
        return None


def verify_model_files(path, model_name):
    """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    if not path or not Path(path).exists():
        return False

    path_obj = Path(path)

    # æ£€æŸ¥å…³é”®æ–‡ä»¶ï¼ˆæ ¹æ®ä¸åŒæ¨¡å‹ç±»å‹ï¼‰
    if model_name == "mineru":
        # MinerU åº”è¯¥åŒ…å« .safetensors æˆ– .bin æ–‡ä»¶
        has_model = any(path_obj.rglob("*.safetensors")) or any(path_obj.rglob("*.bin"))
        if not has_model:
            logger.warning(f"   âš ï¸  No model files (.safetensors/.bin) found in {path}")
            return False

    elif model_name in ["sensevoice", "paraformer"]:
        # ModelScope æ¨¡å‹åº”è¯¥åŒ…å«é…ç½®æ–‡ä»¶
        config_file = path_obj / "configuration.json"
        if not config_file.exists():
            # å°è¯•æŸ¥æ‰¾å…¶ä»–é…ç½®æ–‡ä»¶
            config_file = path_obj / "config.json"
        if not config_file.exists():
            logger.warning(f"   âš ï¸  No configuration file found in {path}")
            return False

    elif model_name == "yolo11":
        # YOLO æ¨¡å‹åº”è¯¥æ˜¯ .pt æ–‡ä»¶
        if not str(path).endswith(".pt"):
            logger.warning(f"   âš ï¸  Invalid YOLO model file: {path}")
            return False

    logger.info(f"   âœ… Model files verified")
    return True


def get_directory_size(path):
    """è·å–ç›®å½•å¤§å°ï¼ˆMBï¼‰"""
    if not path or not Path(path).exists():
        return 0

    path_obj = Path(path)
    if path_obj.is_file():
        return path_obj.stat().st_size / (1024 * 1024)

    total_size = 0
    for file_path in path_obj.rglob("*"):
        if file_path.is_file():
            total_size += file_path.stat().st_size

    return total_size / (1024 * 1024)


def check_model_exists(output_path, config, name):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨

    Args:
        output_path: è¾“å‡ºç›®å½•è·¯å¾„
        config: æ¨¡å‹é…ç½®å­—å…¸
        name: æ¨¡å‹åç§°

    Returns:
        tuple: (exists: bool, reason: str) æ˜¯å¦å­˜åœ¨åŠåŸå› è¯´æ˜
    """
    target_dir = output_path / config["target_dir"]

    if not target_dir.exists():
        return False, "Directory not found"

    # æ ¹æ®ä¸åŒæ¨¡å‹ç±»å‹æ£€æŸ¥å…³é”®æ–‡ä»¶
    if name == "mineru":
        # æ£€æŸ¥ HuggingFace hub ç¼“å­˜
        has_model = any(target_dir.rglob("*.safetensors")) or any(target_dir.rglob("*.bin"))
        return has_model, "Model files found" if has_model else "Model files missing"

    elif name in ["sensevoice", "paraformer"]:
        # æ£€æŸ¥ ModelScope æ¨¡å‹é…ç½®æ–‡ä»¶
        config_files = list(target_dir.rglob("configuration.json"))
        if not config_files:
            config_files = list(target_dir.rglob("config.json"))
        return bool(config_files), "Config found" if config_files else "Config missing"

    elif name == "yolo11":
        # æ£€æŸ¥ YOLO .pt æ–‡ä»¶
        pt_files = list(target_dir.rglob("*.pt"))
        return bool(pt_files), f"{len(pt_files)} .pt files found" if pt_files else "No .pt files"

    # å¯¹äºæœªçŸ¥ç±»å‹ï¼Œæ£€æŸ¥ç›®å½•æ˜¯å¦éç©º
    if any(target_dir.iterdir()):
        return True, "Files found"

    return False, "Directory empty"


def main(output_dir, selected_models=None, force=False):
    """ä¸»å‡½æ•°

    Args:
        output_dir: è¾“å‡ºç›®å½•
        selected_models: é€‰æ‹©çš„æ¨¡å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½å·²å­˜åœ¨çš„æ¨¡å‹
    """
    logger.info("=" * 60)
    logger.info("ğŸš€ Tianshu Model Download Script")
    logger.info("=" * 60)

    output_path = Path(output_dir).resolve()
    output_path.mkdir(parents=True, exist_ok=True)

    logger.info(f"ğŸ“ Output directory: {output_path}")
    if force:
        logger.info("âš ï¸  Force mode: Will re-download existing models")
    logger.info("")

    # ç­›é€‰è¦ä¸‹è½½çš„æ¨¡å‹
    models_to_download = MODELS
    if selected_models:
        selected_list = [m.strip() for m in selected_models.split(",")]
        models_to_download = {k: v for k, v in MODELS.items() if k in selected_list}
        logger.info(f"ğŸ“‹ Selected models: {', '.join(models_to_download.keys())}")
    else:
        logger.info(f"ğŸ“‹ Downloading all models ({len(MODELS)} total)")

    logger.info("")

    manifest = {
        "created": datetime.now().isoformat(),
        "platform": "cpu",
        "output_dir": str(output_path),
        "models": {},
        "total_size_mb": 0
    }

    total_downloaded = 0
    total_skipped = 0
    total_failed = 0

    # ä¸‹è½½æ¯ä¸ªæ¨¡å‹
    for name, config in models_to_download.items():
        logger.info(f"ğŸ“¦ [{name.upper()}] {config['name']}")
        logger.info(f"   {config['description']}")

        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªåŠ¨ä¸‹è½½çš„æ¨¡å‹
            if config.get("auto_download"):
                logger.info(f"   â„¹ï¸  {name} will be downloaded automatically on first run")
                manifest["models"][name] = {
                    "name": config["name"],
                    "status": "auto_download",
                    "description": config["description"]
                }
                logger.info("")
                continue

            # åˆ›å»ºç›®æ ‡ç›®å½•
            target = output_path / config["target_dir"]
            target.mkdir(parents=True, exist_ok=True)

            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨ï¼ˆé™¤éä½¿ç”¨ --forceï¼‰
            if not force:
                exists, reason = check_model_exists(output_path, config, name)
                if exists:
                    size_mb = get_directory_size(target)
                    logger.info(f"   âœ… Already exists ({size_mb:.1f} MB)")
                    logger.info(f"   ğŸ“‚ Path: {target}")
                    manifest["models"][name] = {
                        "name": config["name"],
                        "status": "already_exists",
                        "size_mb": round(size_mb, 2),
                        "path": str(target),
                        "description": config["description"]
                    }
                    manifest["total_size_mb"] += size_mb
                    total_skipped += 1
                    logger.info("")
                    continue
                else:
                    logger.info(f"   â„¹ï¸  Not found: {reason}")

            # ä¸‹è½½æ¨¡å‹
            logger.info(f"   â¬‡ï¸  Downloading...")
            path = None
            if config["source"] == "huggingface":
                path = download_from_huggingface(
                    config["repo_id"],
                    str(target),
                    config.get("filename")
                )
            elif config["source"] == "modelscope":
                path = download_from_modelscope(config["model_id"], str(target))

            if path:
                # éªŒè¯ä¸‹è½½
                if verify_model_files(path, name):
                    size_mb = get_directory_size(path)
                    manifest["models"][name] = {
                        "name": config["name"],
                        "status": "downloaded",
                        "path": str(path),
                        "size_mb": round(size_mb, 2),
                        "description": config["description"]
                    }
                    manifest["total_size_mb"] += size_mb
                    logger.info(f"   âœ… Downloaded successfully ({size_mb:.1f} MB)")
                    logger.info(f"   ğŸ“‚ Path: {path}")
                    total_downloaded += 1
                else:
                    manifest["models"][name] = {
                        "name": config["name"],
                        "status": "verification_failed",
                        "path": str(path) if path else None,
                        "description": config["description"]
                    }
                    total_failed += 1
            else:
                manifest["models"][name] = {
                    "name": config["name"],
                    "status": "download_failed",
                    "error": "Download failed",
                    "description": config["description"]
                }
                total_failed += 1

        except Exception as e:
            logger.error(f"   âŒ Error downloading {name}: {e}")
            manifest["models"][name] = {
                "name": config["name"],
                "status": "error",
                "error": str(e),
                "description": config["description"]
            }
            total_failed += 1

        logger.info("")

    # ä¿å­˜æ¸…å•
    manifest_file = output_path / "manifest.json"
    with open(manifest_file, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2, ensure_ascii=False)

    # è¾“å‡ºæ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“Š Download Summary")
    logger.info("=" * 60)
    logger.info(f"âœ… Successfully downloaded: {total_downloaded} models")
    if total_skipped > 0:
        logger.info(f"â­ï¸  Skipped (already exists): {total_skipped} models")
    logger.info(f"âŒ Failed: {total_failed} models")
    logger.info(f"ğŸ’¾ Total size: {manifest['total_size_mb']:.1f} MB")
    logger.info(f"ğŸ“„ Manifest saved to: {manifest_file}")
    logger.info("")

    if total_failed > 0:
        logger.warning("âš ï¸  Some models failed to download. Please check the errors above.")
        logger.info("   You can re-run this script to retry failed downloads.")
        return 1

    if total_downloaded > 0:
        logger.info("ğŸ‰ All models downloaded successfully!")
    else:
        logger.info("âœ¨ All models are already up to date!")

    logger.info("")
    logger.info("ğŸ“‹ Next steps:")
    logger.info("   1. Package models: tar czf models-offline.tar.gz models-offline/")
    logger.info("   2. Transfer to production server")
    logger.info("   3. Run deployment script: ./deploy-cpu-offline.sh or ./deploy-gpu-offline.sh")
    logger.info("")

    return 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Download all models for Tianshu CPU offline deployment",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Download all models
  python download_models.py --output ./models-offline

  # Download specific models only
  python download_models.py --output ./models-offline --models mineru,sensevoice

  # Force re-download all models (even if they exist)
  python download_models.py --output ./models-offline --force

  # Use custom HuggingFace mirror
  HF_ENDPOINT=https://hf-mirror.com python download_models.py --output ./models-offline
        """
    )
    parser.add_argument(
        "--output",
        default="./models-offline",
        help="Output directory for downloaded models (default: ./models-offline)"
    )
    parser.add_argument(
        "--models",
        help="Comma-separated list of models to download (default: all). Available: "
             + ", ".join(MODELS.keys())
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force re-download all models, even if they already exist"
    )

    args = parser.parse_args()

    try:
        exit_code = main(args.output, args.models, args.force)
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  Download interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
