"""
MinerU Tianshu - MCP Server
å¤©æ¢ MCP åè®®æœåŠ¡å™¨

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° - MCP æ¥å£
é€šè¿‡ Model Context Protocol æš´éœ²æ•°æ®å¤„ç†èƒ½åŠ›

æ”¯æŒåŠŸèƒ½:
- æ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
- Base64 ç¼–ç çš„æ–‡ä»¶ä¼ è¾“
- URL æ–‡ä»¶ä¸‹è½½
- å¼‚æ­¥ä»»åŠ¡å¤„ç†å’ŒçŠ¶æ€æŸ¥è¯¢
- é˜Ÿåˆ—ç»Ÿè®¡å’Œä»»åŠ¡ç®¡ç†
"""

import asyncio
import json
import os
import sys
from typing import Any
from pathlib import Path
import base64

from mcp.server import Server
from mcp.server.sse import SseServerTransport
from mcp.types import Tool, TextContent
from starlette.applications import Starlette
from starlette.routing import Route
import aiohttp
from loguru import logger

# æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰
MAX_FILE_SIZE_BYTES = int(os.getenv("MAX_FILE_SIZE", "0"))  # 0 = ä¸é™åˆ¶
MAX_FILE_SIZE_MB = MAX_FILE_SIZE_BYTES / (1024 * 1024) if MAX_FILE_SIZE_BYTES > 0 else 0
import uvicorn

# API é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# åˆå§‹åŒ– MCP Server
app = Server("mineru-tianshu")


@app.list_tools()
async def list_tools() -> list[Tool]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·"""
    return [
        Tool(
            name="parse_document",
            description="""
è§£ææ–‡æ¡£ï¼ˆPDFã€å›¾ç‰‡ã€Officeæ–‡æ¡£ç­‰ï¼‰ä¸º Markdown æ ¼å¼ã€‚

ğŸ“ æ”¯æŒ 2 ç§æ–‡ä»¶è¾“å…¥æ–¹å¼ï¼š
1. file_base64: Base64 ç¼–ç çš„æ–‡ä»¶å†…å®¹ï¼ˆæ¨èç”¨äºå°æ–‡ä»¶ï¼‰
2. file_url: å…¬ç½‘å¯è®¿é—®çš„æ–‡ä»¶ URLï¼ˆæœåŠ¡å™¨ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰

æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š
- PDF å’Œå›¾ç‰‡ï¼ˆä½¿ç”¨ MinerU GPU åŠ é€Ÿè§£æï¼‰
- Office æ–‡æ¡£ï¼ˆWordã€Excelã€PowerPointï¼‰
- ç½‘é¡µå’Œæ–‡æœ¬ï¼ˆHTMLã€Markdownã€TXTã€CSVï¼‰

åŠŸèƒ½ç‰¹æ€§ï¼š
- å…¬å¼è¯†åˆ«å’Œè¡¨æ ¼è¯†åˆ«
- æ”¯æŒä¸­è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰å¤šè¯­è¨€
- æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§è®¾ç½®
- å¼‚æ­¥å¤„ç†ï¼Œå¯é€‰æ‹©ç­‰å¾…å®Œæˆæˆ–ç¨åæŸ¥è¯¢
            """.strip(),
            inputSchema={
                "type": "object",
                "properties": {
                    # æ–¹å¼ 1: Base64 ç¼–ç ï¼ˆå°æ–‡ä»¶æ¨èï¼‰
                    "file_base64": {
                        "type": "string",
                        "description": "Base64 ç¼–ç çš„æ–‡ä»¶å†…å®¹",
                    },
                    "file_name": {"type": "string", "description": "æ–‡ä»¶åï¼ˆä½¿ç”¨ file_base64 æ—¶å¿…éœ€ï¼‰"},
                    # æ–¹å¼ 2: URL ä¸‹è½½
                    "file_url": {"type": "string", "description": "æ–‡ä»¶çš„å…¬ç½‘ URLï¼ˆæœåŠ¡å™¨ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰"},
                    # è§£æé€‰é¡¹
                    "backend": {
                        "type": "string",
                        "enum": ["pipeline", "vlm-transformers", "vlm-vllm-engine"],
                        "description": "å¤„ç†åç«¯ï¼Œé»˜è®¤: pipeline",
                        "default": "pipeline",
                    },
                    "lang": {
                        "type": "string",
                        "enum": ["ch", "en", "korean", "japan"],
                        "description": "æ–‡æ¡£è¯­è¨€ï¼Œé»˜è®¤: ch",
                        "default": "ch",
                    },
                    "method": {
                        "type": "string",
                        "enum": ["auto", "txt", "ocr"],
                        "description": "è§£ææ–¹æ³•ï¼Œé»˜è®¤: auto",
                        "default": "auto",
                    },
                    "formula_enable": {
                        "type": "boolean",
                        "description": "æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«ï¼Œé»˜è®¤: true",
                        "default": True,
                    },
                    "table_enable": {"type": "boolean", "description": "æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«ï¼Œé»˜è®¤: true", "default": True},
                    "priority": {
                        "type": "integer",
                        "description": "ä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆ0-100ï¼‰ï¼Œæ•°å­—è¶Šå¤§è¶Šä¼˜å…ˆï¼Œé»˜è®¤: 0",
                        "default": 0,
                        "minimum": 0,
                        "maximum": 100,
                    },
                    "wait_for_completion": {
                        "type": "boolean",
                        "description": "æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œé»˜è®¤: true",
                        "default": True,
                    },
                    "max_wait_seconds": {
                        "type": "integer",
                        "description": "æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤: 300",
                        "default": 300,
                        "minimum": 10,
                        "maximum": 3600,
                    },
                },
                # å¿…é¡»æä¾› 2 ç§æ–¹å¼ä¹‹ä¸€
                "oneOf": [{"required": ["file_base64", "file_name"]}, {"required": ["file_url"]}],
            },
        ),
        Tool(
            name="get_task_status",
            description="""
æŸ¥è¯¢æ–‡æ¡£è§£æä»»åŠ¡çš„çŠ¶æ€å’Œç»“æœã€‚

å¯ä»¥æŸ¥è¯¢ä»»åŠ¡çš„ï¼š
- å½“å‰çŠ¶æ€ï¼ˆpending/processing/completed/failed/cancelledï¼‰
- å¤„ç†è¿›åº¦å’Œæ—¶é—´ä¿¡æ¯
- é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
- è§£æç»“æœå†…å®¹ï¼ˆå¦‚æœå®Œæˆï¼‰
            """.strip(),
            inputSchema={
                "type": "object",
                "properties": {
                    "task_id": {"type": "string", "description": "ä»»åŠ¡ IDï¼ˆç”± parse_document è¿”å›ï¼‰"},
                    "include_content": {
                        "type": "boolean",
                        "description": "æ˜¯å¦åŒ…å«å®Œæ•´çš„è§£æç»“æœå†…å®¹ï¼Œé»˜è®¤: true",
                        "default": True,
                    },
                },
                "required": ["task_id"],
            },
        ),
        Tool(
            name="list_tasks",
            description="""
åˆ—å‡ºæœ€è¿‘çš„æ–‡æ¡£è§£æä»»åŠ¡ã€‚

å¯ä»¥æŒ‰çŠ¶æ€ç­›é€‰ï¼ŒæŸ¥çœ‹ä»»åŠ¡é˜Ÿåˆ—æƒ…å†µã€‚
            """.strip(),
            inputSchema={
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["pending", "processing", "completed", "failed", "cancelled"],
                        "description": "ç­›é€‰æŒ‡å®šçŠ¶æ€çš„ä»»åŠ¡ï¼ˆå¯é€‰ï¼Œä¸å¡«åˆ™è¿”å›æ‰€æœ‰çŠ¶æ€ï¼‰",
                    },
                    "limit": {
                        "type": "integer",
                        "description": "è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤: 10",
                        "default": 10,
                        "minimum": 1,
                        "maximum": 100,
                    },
                },
            },
        ),
        Tool(
            name="get_queue_stats",
            description="""
è·å–ä»»åŠ¡é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯ã€‚

è¿”å›å„ä¸ªçŠ¶æ€çš„ä»»åŠ¡æ•°é‡ï¼Œäº†è§£ç³»ç»Ÿè´Ÿè½½æƒ…å†µã€‚
            """.strip(),
            inputSchema={"type": "object", "properties": {}},
        ),
    ]


@app.call_tool()
async def call_tool(name: str, arguments: Any) -> list[TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    try:
        logger.info(f"ğŸ”§ Tool called: {name}")

        if name == "parse_document":
            return await parse_document(arguments)
        elif name == "get_task_status":
            return await get_task_status(arguments)
        elif name == "list_tasks":
            return await list_tasks(arguments)
        elif name == "get_queue_stats":
            return await get_queue_stats(arguments)
        else:
            return [TextContent(type="text", text=json.dumps({"error": f"Unknown tool: {name}"}, indent=2))]
    except Exception as e:
        logger.error(f"âŒ Tool call failed: {name}, error: {e}")
        logger.exception(e)
        return [TextContent(type="text", text=json.dumps({"error": str(e), "tool": name}, indent=2))]


async def parse_document(args: dict) -> list[TextContent]:
    """è§£ææ–‡æ¡£ - æ”¯æŒ Base64 å’Œ URL ä¸¤ç§è¾“å…¥æ–¹å¼"""
    async with aiohttp.ClientSession() as session:
        temp_file_path = None
        file_data = None
        file_name = None

        try:
            # æ–¹å¼ 1: Base64 ç¼–ç 
            if "file_base64" in args:
                logger.info("ğŸ“¦ Receiving file via Base64 encoding")

                try:
                    # Security: Safe use of base64 for file transmission via MCP protocol
                    # This is legitimate business logic, not code obfuscation
                    file_content = base64.b64decode(args["file_base64"])
                except Exception as e:
                    return [
                        TextContent(
                            type="text", text=json.dumps({"error": f"Invalid base64 encoding: {str(e)}"}, indent=2)
                        )
                    ]

                file_name = args["file_name"]

                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœè®¾ç½®äº†é™åˆ¶ï¼‰
                size_mb = len(file_content) / (1024 * 1024)
                if MAX_FILE_SIZE_BYTES > 0 and size_mb > MAX_FILE_SIZE_MB:
                    return [
                        TextContent(
                            type="text",
                            text=json.dumps(
                                {
                                    "error": f"File too large ({size_mb:.1f}MB). Maximum size is {MAX_FILE_SIZE_MB:.0f}MB."
                                },
                                indent=2,
                            ),
                        )
                    ]

                logger.info(f"ğŸ“¦ File: {file_name}, Size: {size_mb:.2f}MB")

                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆä½¿ç”¨å…±äº«ä¸Šä¼ ç›®å½•ï¼‰
                import uuid
                import os

                project_root = Path(__file__).parent.parent
                default_upload = project_root / "data" / "uploads"
                upload_dir = Path(os.getenv("UPLOAD_PATH", str(default_upload)))
                upload_dir.mkdir(parents=True, exist_ok=True)
                temp_file_path = upload_dir / f"{uuid.uuid4().hex}_{file_name}"
                temp_file_path.write_bytes(file_content)
                file_data = open(temp_file_path, "rb")

            # æ–¹å¼ 2: URL ä¸‹è½½
            elif "file_url" in args:
                url = args["file_url"]
                logger.info(f"ğŸŒ Downloading file from URL: {url}")

                try:
                    async with session.get(url, timeout=aiohttp.ClientTimeout(total=60)) as resp:
                        if resp.status != 200:
                            return [
                                TextContent(
                                    type="text",
                                    text=json.dumps(
                                        {"error": f"Failed to download file from {url}", "status_code": resp.status},
                                        indent=2,
                                    ),
                                )
                            ]

                        # ä» URL æ¨æ–­æ–‡ä»¶å
                        file_name = Path(url).name or "downloaded_file"

                        # å°è¯•ä» Content-Disposition è·å–æ–‡ä»¶å
                        if "content-disposition" in resp.headers:
                            import re

                            cd = resp.headers["content-disposition"]
                            match = re.search(r'filename[*]?=["\']?([^"\';\r\n]+)', cd)
                            if match:
                                file_name = match.group(1)

                        # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
                        file_content = await resp.read()
                        size_mb = len(file_content) / (1024 * 1024)

                        if MAX_FILE_SIZE_BYTES > 0 and size_mb > MAX_FILE_SIZE_MB:
                            return [
                                TextContent(
                                    type="text",
                                    text=json.dumps(
                                        {
                                            "error": f"Downloaded file too large ({size_mb:.1f}MB). Maximum size is {MAX_FILE_SIZE_MB:.0f}MB."
                                        },
                                        indent=2,
                                    ),
                                )
                            ]

                        logger.info(f"ğŸ“¦ Downloaded: {file_name}, Size: {size_mb:.2f}MB")

                        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆä½¿ç”¨å…±äº«ä¸Šä¼ ç›®å½•ï¼‰
                        import uuid
                        import os

                        project_root = Path(__file__).parent.parent
                        default_upload = project_root / "data" / "uploads"
                        upload_dir = Path(os.getenv("UPLOAD_PATH", str(default_upload)))
                        upload_dir.mkdir(parents=True, exist_ok=True)
                        temp_file_path = upload_dir / f"{uuid.uuid4().hex}_{file_name}"
                        temp_file_path.write_bytes(file_content)
                        file_data = open(temp_file_path, "rb")

                except asyncio.TimeoutError:
                    return [
                        TextContent(
                            type="text", text=json.dumps({"error": f"Timeout downloading file from {url}"}, indent=2)
                        )
                    ]
                except Exception as e:
                    return [
                        TextContent(
                            type="text", text=json.dumps({"error": f"Failed to download file: {str(e)}"}, indent=2)
                        )
                    ]

            else:
                return [
                    TextContent(
                        type="text", text=json.dumps({"error": "Must provide either file_base64 or file_url"}, indent=2)
                    )
                ]

            # æäº¤ä»»åŠ¡åˆ° API Server
            form_data = aiohttp.FormData()
            form_data.add_field("file", file_data, filename=file_name)
            form_data.add_field("backend", args.get("backend", "pipeline"))
            form_data.add_field("lang", args.get("lang", "ch"))
            form_data.add_field("method", args.get("method", "auto"))
            form_data.add_field("formula_enable", str(args.get("formula_enable", True)).lower())
            form_data.add_field("table_enable", str(args.get("table_enable", True)).lower())
            form_data.add_field("priority", str(args.get("priority", 0)))

            logger.info(f"ğŸ“¤ Submitting task for: {file_name}")

            async with session.post(f"{API_BASE_URL}/api/v1/tasks/submit", data=form_data) as resp:
                if resp.status != 200:
                    error_text = await resp.text()
                    return [
                        TextContent(
                            type="text",
                            text=json.dumps(
                                {"error": "Failed to submit task", "details": error_text, "status_code": resp.status},
                                indent=2,
                            ),
                        )
                    ]

                result = await resp.json()
                task_id = result["task_id"]
                logger.info(f"âœ… Task submitted: {task_id}")

            # æ˜¯å¦ç­‰å¾…å®Œæˆ
            if not args.get("wait_for_completion", True):
                return [
                    TextContent(
                        type="text",
                        text=json.dumps(
                            {
                                "status": "submitted",
                                "task_id": task_id,
                                "file_name": file_name,
                                "message": "Task submitted successfully. Use get_task_status to check progress.",
                            },
                            indent=2,
                            ensure_ascii=False,
                        ),
                    )
                ]

            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            logger.info(f"â³ Waiting for task completion: {task_id}")
            max_wait = args.get("max_wait_seconds", 300)
            poll_interval = 2
            elapsed = 0

            while elapsed < max_wait:
                async with session.get(f"{API_BASE_URL}/api/v1/tasks/{task_id}") as resp:
                    if resp.status != 200:
                        return [
                            TextContent(
                                type="text",
                                text=json.dumps({"error": "Failed to query task status", "task_id": task_id}, indent=2),
                            )
                        ]

                    task_status = await resp.json()
                    status = task_status["status"]

                    if status == "completed":
                        # ä»»åŠ¡å®Œæˆï¼Œè¿”å›ç»“æœ
                        logger.info(f"âœ… Task completed: {task_id}")
                        content = task_status.get("data", {}).get("content", "") if task_status.get("data") else ""

                        return [
                            TextContent(
                                type="text",
                                text=json.dumps(
                                    {
                                        "status": "completed",
                                        "task_id": task_id,
                                        "file_name": file_name,
                                        "content": content,
                                        "processing_time": _calculate_processing_time(task_status),
                                        "created_at": task_status.get("created_at"),
                                        "started_at": task_status.get("started_at"),
                                        "completed_at": task_status.get("completed_at"),
                                    },
                                    indent=2,
                                    ensure_ascii=False,
                                ),
                            )
                        ]

                    elif status == "failed":
                        logger.error(f"âŒ Task failed: {task_id}")
                        return [
                            TextContent(
                                type="text",
                                text=json.dumps(
                                    {
                                        "status": "failed",
                                        "task_id": task_id,
                                        "file_name": file_name,
                                        "error": task_status.get("error_message", "Unknown error"),
                                        "created_at": task_status.get("created_at"),
                                        "started_at": task_status.get("started_at"),
                                        "completed_at": task_status.get("completed_at"),
                                    },
                                    indent=2,
                                    ensure_ascii=False,
                                ),
                            )
                        ]

                    elif status == "cancelled":
                        logger.warning(f"âš ï¸ Task cancelled: {task_id}")
                        return [
                            TextContent(
                                type="text",
                                text=json.dumps(
                                    {"status": "cancelled", "task_id": task_id, "file_name": file_name},
                                    indent=2,
                                    ensure_ascii=False,
                                ),
                            )
                        ]

                    elif status in ["pending", "processing"]:
                        await asyncio.sleep(poll_interval)
                        elapsed += poll_interval
                        if elapsed % 10 == 0:  # æ¯ 10 ç§’è®°å½•ä¸€æ¬¡
                            logger.info(f"â³ Task {task_id} status: {status}, elapsed: {elapsed}s")

                    else:
                        return [
                            TextContent(
                                type="text",
                                text=json.dumps(
                                    {"status": status, "task_id": task_id, "file_name": file_name},
                                    indent=2,
                                    ensure_ascii=False,
                                ),
                            )
                        ]

            # è¶…æ—¶
            logger.warning(f"â° Task timeout: {task_id}")
            return [
                TextContent(
                    type="text",
                    text=json.dumps(
                        {
                            "status": "timeout",
                            "task_id": task_id,
                            "file_name": file_name,
                            "message": f"Task did not complete within {max_wait} seconds. Use get_task_status to check later.",
                        },
                        indent=2,
                        ensure_ascii=False,
                    ),
                )
            ]

        finally:
            # æ¸…ç†æ–‡ä»¶å’Œä¸´æ—¶æ–‡ä»¶
            if file_data is not None:
                try:
                    if not file_data.closed:
                        file_data.close()
                        logger.debug(f"Closed file handle for: {file_name}")
                except Exception as e:
                    logger.warning(f"Failed to close file handle: {e}")
            if temp_file_path is not None:
                try:
                    if temp_file_path.exists():
                        temp_file_path.unlink()
                        logger.info(f"Cleaned temp file: {temp_file_path}")
                except Exception as e:
                    logger.warning(f"Failed to delete temp file: {e}")


async def get_task_status(args: dict) -> list[TextContent]:
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task_id = args["task_id"]
    include_content = args.get("include_content", True)

    logger.info(f"ğŸ“Š Querying task status: {task_id}")

    async with aiohttp.ClientSession() as session:
        async with session.get(f"{API_BASE_URL}/api/v1/tasks/{task_id}") as resp:
            if resp.status == 404:
                return [TextContent(type="text", text=json.dumps({"error": f"Task not found: {task_id}"}, indent=2))]

            if resp.status != 200:
                return [
                    TextContent(
                        type="text",
                        text=json.dumps({"error": "Failed to query task status", "task_id": task_id}, indent=2),
                    )
                ]

            task = await resp.json()

            # æ„å»ºå“åº”
            response = {
                "task_id": task_id,
                "status": task["status"],
                "file_name": task["file_name"],
                "backend": task["backend"],
                "priority": task["priority"],
                "created_at": task["created_at"],
                "started_at": task["started_at"],
                "completed_at": task["completed_at"],
                "worker_id": task["worker_id"],
                "retry_count": task["retry_count"],
            }

            if task.get("error_message"):
                response["error_message"] = task["error_message"]

            if include_content and task["status"] == "completed" and task.get("data"):
                response["content"] = task["data"].get("content", "")
                response["processing_time"] = _calculate_processing_time(task)
                if task["data"].get("markdown_file"):
                    response["markdown_file"] = task["data"]["markdown_file"]

            return [TextContent(type="text", text=json.dumps(response, indent=2, ensure_ascii=False))]


async def list_tasks(args: dict) -> list[TextContent]:
    """åˆ—å‡ºä»»åŠ¡"""
    status = args.get("status")
    limit = args.get("limit", 10)

    logger.info(f"ğŸ“‹ Listing tasks: status={status}, limit={limit}")

    params = {"limit": limit}
    if status:
        params["status"] = status

    async with aiohttp.ClientSession() as session:
        async with session.get(f"{API_BASE_URL}/api/v1/queue/tasks", params=params) as resp:
            if resp.status != 200:
                return [TextContent(type="text", text=json.dumps({"error": "Failed to list tasks"}, indent=2))]

            result = await resp.json()
            tasks = result["tasks"]

            # ç®€åŒ–ä»»åŠ¡ä¿¡æ¯
            simplified_tasks = [
                {
                    "task_id": t["task_id"],
                    "file_name": t["file_name"],
                    "status": t["status"],
                    "backend": t["backend"],
                    "priority": t["priority"],
                    "created_at": t["created_at"],
                    "started_at": t["started_at"],
                    "completed_at": t["completed_at"],
                    "worker_id": t["worker_id"],
                }
                for t in tasks
            ]

            return [
                TextContent(
                    type="text",
                    text=json.dumps(
                        {"count": len(simplified_tasks), "tasks": simplified_tasks}, indent=2, ensure_ascii=False
                    ),
                )
            ]


async def get_queue_stats(args: dict) -> list[TextContent]:
    """è·å–é˜Ÿåˆ—ç»Ÿè®¡"""
    logger.info("ğŸ“Š Getting queue stats")

    async with aiohttp.ClientSession() as session:
        async with session.get(f"{API_BASE_URL}/api/v1/queue/stats") as resp:
            if resp.status != 200:
                return [TextContent(type="text", text=json.dumps({"error": "Failed to get queue stats"}, indent=2))]

            result = await resp.json()

            return [
                TextContent(
                    type="text",
                    text=json.dumps(
                        {
                            "stats": result["stats"],
                            "total": result.get("total", sum(result["stats"].values())),
                            "timestamp": result.get("timestamp"),
                        },
                        indent=2,
                        ensure_ascii=False,
                    ),
                )
            ]


def _calculate_processing_time(task: dict) -> str:
    """è®¡ç®—å¤„ç†æ—¶é—´"""
    from datetime import datetime

    if task.get("started_at") and task.get("completed_at"):
        try:
            start = datetime.fromisoformat(task["started_at"])
            end = datetime.fromisoformat(task["completed_at"])
            duration = (end - start).total_seconds()
            return f"{duration:.2f} seconds"
        except Exception:
            return "N/A"
    return "N/A"


async def main():
    """å¯åŠ¨ MCP Server (SSE æ¨¡å¼)"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Starting MinerU Tianshu MCP Server")
    logger.info("=" * 60)
    logger.info(f"ğŸ“¡ API Base URL: {API_BASE_URL}")

    # åˆ›å»º SSE Transport
    sse = SseServerTransport("/messages")

    # SSE å¤„ç†å‡½æ•°
    async def handle_sse(request):
        async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
            await app.run(streams[0], streams[1], app.create_initialization_options())

    # POST æ¶ˆæ¯å¤„ç†å‡½æ•°
    async def handle_messages(request):
        await sse.handle_post_message(request.scope, request.receive, request._send)

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹
    async def health_check(request):
        from starlette.responses import JSONResponse

        return JSONResponse(
            {
                "status": "healthy",
                "service": "MinerU Tianshu MCP Server",
                "version": "1.0.0",
                "endpoints": {"sse": "/sse", "messages": "/messages (POST)", "health": "/health"},
                "tools": ["parse_document", "get_task_status", "list_tasks", "get_queue_stats"],
                "api_base_url": API_BASE_URL,
            }
        )

    # åˆ›å»º Starlette åº”ç”¨
    starlette_app = Starlette(
        routes=[
            Route("/sse", endpoint=handle_sse),
            Route("/messages", endpoint=handle_messages, methods=["POST"]),
            Route("/health", endpoint=health_check, methods=["GET"]),
            Route("/", endpoint=health_check, methods=["GET"]),  # æ ¹è·¯å¾„ä¹Ÿè¿”å›å¥åº·æ£€æŸ¥
        ]
    )

    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port = int(os.getenv("MCP_PORT", "8002"))

    logger.info(f"ğŸŒ MCP Server listening on http://{host}:{port}")
    logger.info(f"ğŸ“¡ SSE endpoint: http://{host}:{port}/sse")
    logger.info(f"ğŸ“® Messages endpoint: http://{host}:{port}/messages")
    logger.info(f"ğŸ¥ Health check: http://{host}:{port}/health")
    logger.info("ğŸ“š Available tools: parse_document, get_task_status, list_tasks, get_queue_stats")
    logger.info("=" * 60)

    config = uvicorn.Config(starlette_app, host=host, port=port, log_level="info")
    server = uvicorn.Server(config)
    await server.serve()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ MCP Server stopped by user")
    except Exception as e:
        logger.error(f"âŒ MCP Server failed to start: {e}")
        logger.exception(e)
        sys.exit(1)
