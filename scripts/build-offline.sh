#!/bin/bash
# Tianshu ç»Ÿä¸€ç¦»çº¿é•œåƒæ„å»ºè„šæœ¬
# æ„å»º GPU ç‰ˆæœ¬é•œåƒï¼ˆè‡ªåŠ¨é™çº§åˆ° CPUï¼‰
# ç”¨äºåœ¨è”ç½‘ç¯å¢ƒä¸­æ„å»ºé•œåƒå¹¶å¤ç”¨å·²ä¸‹è½½çš„æ¨¡å‹

set -e

# ============================================================================
# é…ç½®
# ============================================================================
PLATFORM="${PLATFORM:-amd64}"
OUTPUT_DIR="./docker-images"
MODELS_DIR="./models-offline"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================
main() {
    log_info "=========================================="
    log_info "ğŸš€ Building Tianshu Unified Image (GPU with CPU fallback)"
    log_info "=========================================="
    log_info "Platform: linux/$PLATFORM"
    log_info "Output: $OUTPUT_DIR"
    echo ""

    # 1. æ£€æŸ¥ Docker ç¯å¢ƒ
    log_info "ğŸ“‹ Checking Docker environment..."
    if ! command -v docker &> /dev/null; then
        log_error "Docker is not installed!"
        exit 1
    fi

    if ! command -v docker-compose &> /dev/null; then
        log_warning "docker-compose not found, trying docker compose..."
        if ! docker compose version &> /dev/null; then
            log_error "Docker Compose is not installed!"
            exit 1
        fi
    fi

    DOCKER_VERSION=$(docker --version)
    log_success "Docker: $DOCKER_VERSION"
    echo ""

    # 2. æ£€æŸ¥ NVIDIA ç¯å¢ƒï¼ˆå¯é€‰ï¼Œä»…æç¤ºï¼‰
    log_info "ğŸ” Checking NVIDIA environment (optional)..."
    if command -v nvidia-smi &> /dev/null; then
        NVIDIA_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null | head -1)
        log_success "NVIDIA Driver: $NVIDIA_VERSION"
        log_info "Note: GPU detected but not required for building"
    else
        log_info "GPU not detected - building unified image anyway"
        log_info "Built image will work on both GPU and CPU servers"
    fi
    echo ""

    # 3. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
    log_info "ğŸ“¦ Checking models..."
    if [ ! -d "$MODELS_DIR" ] || [ -z "$(ls -A $MODELS_DIR 2>/dev/null)" ]; then
        log_warning "Models directory not found or empty!"
        log_info "Running model download script..."
        echo ""

        # æ£€æŸ¥ Python å’Œä¾èµ–
        if ! command -v python3 &> /dev/null; then
            log_error "Python 3 is not installed!"
            exit 1
        fi

        # å®‰è£…å¿…è¦çš„ä¾èµ–ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        python3 -m pip install --quiet huggingface-hub modelscope loguru 2>/dev/null || true

        # æ‰§è¡Œä¸‹è½½
        python3 backend/download_models.py --output "$MODELS_DIR"

        if [ $? -eq 0 ]; then
            log_success "Models downloaded successfully"
        else
            log_error "Model download failed!"
            log_info "Please run manually: python3 backend/download_models.py --output $MODELS_DIR"
            exit 1
        fi
    else
        log_success "Models directory found: $MODELS_DIR"
        log_info "Skipping model download (already exists)"
        log_info "Use --force to re-download: python3 backend/download_models.py --output $MODELS_DIR --force"
    fi
    echo ""

    # 4. æ„å»ºåç«¯ç»Ÿä¸€é•œåƒ
    log_info "ğŸ“¦ Building backend unified image (GPU with CPU fallback)..."
    log_info "   This may take 60-90 minutes..."
    log_info "   Using Dockerfile: backend/Dockerfile (CUDA-based, auto-adapts to CPU)"
    echo ""

    DOCKER_BUILDKIT=1 docker buildx build \
        --platform linux/$PLATFORM \
        --file backend/Dockerfile \
        --tag tianshu-backend:latest \
        --load \
        .

    log_success "Backend unified image built successfully"
    echo ""

    # 5. æ„å»ºå‰ç«¯é•œåƒ
    log_info "ğŸ“¦ Building frontend image..."
    echo ""

    DOCKER_BUILDKIT=1 docker buildx build \
        --platform linux/$PLATFORM \
        --file frontend/Dockerfile \
        --tag tianshu-frontend:latest \
        --load \
        .

    log_success "Frontend image built successfully"
    echo ""

    # 6. æ‹‰å– RustFS é•œåƒï¼ˆæ˜ç¡®æŒ‡å®š amd64 å¹³å°ï¼‰
    log_info "ğŸ“¥ Pulling RustFS image (platform: linux/$PLATFORM)..."
    docker pull --platform "linux/$PLATFORM" rustfs/rustfs:latest
    log_success "RustFS image pulled successfully"
    echo ""

    # 7. å¯¼å‡ºé•œåƒ
    log_info "ğŸ’¾ Exporting images..."
    mkdir -p "$OUTPUT_DIR"

    log_info "   Exporting backend unified image (this may take 10-20 minutes)..."
    docker save tianshu-backend:latest | gzip > "$OUTPUT_DIR/tianshu-backend-$PLATFORM.tar.gz" &
    PID_BACKEND=$!

    log_info "   Exporting frontend image..."
    docker save tianshu-frontend:latest | gzip > "$OUTPUT_DIR/tianshu-frontend-$PLATFORM.tar.gz" &
    PID_FRONTEND=$!

    log_info "   Exporting rustfs image..."
    docker save rustfs/rustfs:latest | gzip > "$OUTPUT_DIR/rustfs-$PLATFORM.tar.gz" &
    PID_RUSTFS=$!

    # ç­‰å¾…æ‰€æœ‰å¯¼å‡ºå®Œæˆ
    wait $PID_BACKEND
    wait $PID_FRONTEND
    wait $PID_RUSTFS

    log_success "All images exported successfully"
    echo ""

    # 8. å¤„ç†æ¨¡å‹æ–‡ä»¶
    log_info "ğŸ“¦ Handling models..."

    if [ -d "$MODELS_DIR" ] && [ ! -f "$OUTPUT_DIR/models-offline.tar.gz" ]; then
        log_info "Packaging models..."
        tar czf "$OUTPUT_DIR/models-offline.tar.gz" "$MODELS_DIR/"
        log_success "Models packaged successfully"
    else
        log_warning "Models directory not found or already packaged"
    fi
    echo ""

    # 9. å¤åˆ¶é…ç½®æ–‡ä»¶
    log_info "ğŸ“‹ Copying configuration files..."
    cp docker-compose.yml "$OUTPUT_DIR/"
    cp docker-compose.cpu.yml "$OUTPUT_DIR/" 2>/dev/null || log_warning "docker-compose.cpu.yml not found, skipping"
    cp .env.example "$OUTPUT_DIR/" 2>/dev/null || log_warning ".env.example not found, skipping"
    cp scripts/deploy-offline.sh "$OUTPUT_DIR/" 2>/dev/null || log_warning "deploy-offline.sh not found, skipping"
    cp scripts/deploy-offline-cpu.sh "$OUTPUT_DIR/" 2>/dev/null || log_warning "deploy-offline-cpu.sh not found, skipping"
    chmod +x "$OUTPUT_DIR/deploy-offline.sh" 2>/dev/null || true
    chmod +x "$OUTPUT_DIR/deploy-offline-cpu.sh" 2>/dev/null || true
    log_success "Configuration files copied"
    echo ""

    # 10. æ˜¾ç¤ºç»“æœ
    log_info "=========================================="
    log_success "âœ… Build Complete!"
    log_info "=========================================="
    echo ""
    log_info "ğŸ“¦ Files in $OUTPUT_DIR:"
    ls -lh "$OUTPUT_DIR/"
    echo ""

    # è®¡ç®—æ€»å¤§å°
    TOTAL_SIZE=$(du -sh "$OUTPUT_DIR" | cut -f1)
    log_info "ğŸ’¾ Total size: $TOTAL_SIZE"
    echo ""

    # 11. æ˜¾ç¤ºä¸‹ä¸€æ­¥
    log_info "ğŸ“‹ Next steps:"
    echo ""
    echo "  1. Verify unified image:"
    echo "     docker images | grep tianshu-backend"
    echo ""
    echo "  2. Transfer files to production server:"
    echo "     rsync -avz --progress $OUTPUT_DIR/ user@server:/deploy/"
    echo ""
    echo "  3. Or use scp for individual files:"
    echo "     scp $OUTPUT_DIR/*.tar.gz user@server:/deploy/"
    echo ""
    echo "  4. On production server, run:"
    echo "     cd /deploy"
    echo "     ./deploy-offline.sh"
    echo ""
    echo "     (Script will automatically detect GPU/CPU and deploy accordingly)"
    echo ""
    log_success "Build script completed successfully!"
    echo ""
    log_info "â„¹ï¸  This unified image works on:"
    echo "     - Servers with NVIDIA GPU (auto-acceleration)"
    echo "     - Servers without GPU (auto-fallback to CPU)"
    echo "     - No need to choose - it auto-adapts!"
}

# æ•è·ä¸­æ–­ä¿¡å·
trap 'log_warning "Build interrupted by user"; exit 130' SIGINT SIGTERM

# æ‰§è¡Œä¸»å‡½æ•°
main
