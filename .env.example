# ============================================================================
# Tianshu (天枢) - 统一环境变量配置（GPU 自动适配 CPU）
# ============================================================================
#
# 使用方式：
#   1. 复制此文件为 .env: cp .env.example .env
#   2. 根据实际情况修改配置
#   3. 使用 docker compose up -d 启动服务（自动适配 GPU/CPU）
#
# ============================================================================

# ----------------------------------------------------------------------------
# 应用配置
# ----------------------------------------------------------------------------
API_PORT=8000
WORKER_PORT=8001
MCP_PORT=8002
FRONTEND_PORT=80

LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# JWT 认证配置（重要：生产环境请修改！）
# ----------------------------------------------------------------------------
# 生成方式: openssl rand -hex 32
JWT_SECRET_KEY=your-secret-key-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ----------------------------------------------------------------------------
# CORS 配置
# ----------------------------------------------------------------------------
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:80

# ----------------------------------------------------------------------------
# 设备模式配置（自动检测）
# ----------------------------------------------------------------------------
# auto: 自动检测 GPU，有则用 GPU，无则用 CPU（推荐）
# gpu: 强制使用 GPU（如果没有 GPU 会报错）
# cpu: 强制使用 CPU（即使有 GPU 也不用）
DEVICE_MODE=auto
MINERU_DEVICE_MODE=auto

# ----------------------------------------------------------------------------
# GPU 配置（仅在有 GPU 时生效）
# ----------------------------------------------------------------------------
# 如果有多个 GPU，可以指定使用哪些 GPU
# CUDA_VISIBLE_DEVICES=0        # 只使用 GPU 0
# CUDA_VISIBLE_DEVICES=0,1      # 使用 GPU 0 和 1
# CUDA_VISIBLE_DEVICES=""       # 使用所有 GPU（默认）

# Worker 配置（GPU 优化）
WORKER_GPUS=1              # GPU 数量（CPU 模式忽略）
MAX_BATCH_SIZE=4           # 批处理大小（CPU 模式自动降为 1）
WORKER_TIMEOUT=300         # 超时时间（GPU 5分钟，CPU 自动调整为 10分钟）

# GPU 资源限制
# 建议根据 GPU 显存配置调整：
#   - 8GB 显存：LIMIT=16G, RESERVATION=8G
#   - 12-16GB 显存：LIMIT=24G, RESERVATION=12G
#   - 24GB+ 显存：LIMIT=32G, RESERVATION=16G
#   - CPU 模式：LIMIT=16G, RESERVATION=8G
WORKER_MEMORY_LIMIT=32G
WORKER_MEMORY_RESERVATION=16G

# ----------------------------------------------------------------------------
# CPU 资源限制（根据服务器 CPU 核心数调整）
# ----------------------------------------------------------------------------
# ⚠️ 重要：请根据您的服务器实际 CPU 核心数调整这些值
# 查看 CPU 核心数：
#   Linux/Mac: nproc 或 lscpu
#   Docker: docker info | grep CPUs
#
# 各服务 CPU 限制建议：
#   - Worker: 主要处理服务，需要较多 CPU（默认 8 核）
#   - Backend: API 服务，中等 CPU（默认 4 核）
#   - MCP: 轻量服务（默认 2 核）
#   - Frontend: 静态服务（默认 1 核）
#   总计默认：15 核
#
# 配置示例（根据 CPU 核心数）：
#   8 核机器：WORKER=4, BACKEND=2, MCP=1, FRONTEND=1（总计 8）
#   10 核机器：WORKER=6, BACKEND=2, MCP=1, FRONTEND=1（总计 10）
#   16 核机器：WORKER=10, BACKEND=4, MCP=1, FRONTEND=1（总计 16）
#   32 核机器：WORKER=20, BACKEND=8, MCP=2, FRONTEND=2（总计 32）

# Worker 服务 CPU 限制
WORKER_CPU_LIMIT=8.0           # CPU 核心数上限（默认 8 核）
WORKER_CPU_RESERVATION=4.0     # CPU 核心数预留（默认 4 核）

# Backend 服务 CPU 限制
BACKEND_CPU_LIMIT=4.0          # CPU 核心数上限（默认 4 核）
BACKEND_MEMORY_LIMIT=8G        # 内存上限
BACKEND_MEMORY_RESERVATION=4G  # 内存预留

# MCP 服务 CPU 限制（可选服务）
MCP_CPU_LIMIT=2.0              # CPU 核心数上限（默认 2 核）
MCP_MEMORY_LIMIT=2G            # 内存上限

# Frontend 服务 CPU 限制
FRONTEND_CPU_LIMIT=1.0         # CPU 核心数上限（默认 1 核）
FRONTEND_MEMORY_LIMIT=512M     # 内存上限

# ----------------------------------------------------------------------------
# 模型配置（离线模式，请勿修改）
# ----------------------------------------------------------------------------
MODEL_DOWNLOAD_SOURCE=local
HF_OFFLINE=1
MODEL_PATH=/app/models
OUTPUT_PATH=/app/output

# 如果需要在线下载模型（首次运行时），可以设置：
# MODEL_DOWNLOAD_SOURCE=modelscope  # 或 huggingface
# HF_OFFLINE=0
# HF_ENDPOINT=https://hf-mirror.com

# ----------------------------------------------------------------------------
# 文件配置
# ----------------------------------------------------------------------------
# 最大文件大小（字节，0 表示不限制）
MAX_FILE_SIZE=0

# Nginx 文件上传大小限制（0 表示不限制）
NGINX_CLIENT_MAX_BODY_SIZE=0

# ----------------------------------------------------------------------------
# PDF 拆分配置（大文件并行处理）
# ----------------------------------------------------------------------------
# 是否启用 PDF 自动拆分（true/false）
PDF_SPLIT_ENABLED=true

# PDF 拆分阈值（页数）
# 超过此页数的 PDF 会自动拆分为多个子任务并行处理
# GPU 模式下可以设置较大的阈值，因为处理速度快
# CPU 模式下建议保持默认值
PDF_SPLIT_THRESHOLD_PAGES=500

# PDF 拆分块大小（页数）
# 每个子任务处理的页数
# GPU 模式下可以设置较大的值，CPU 模式下建议保持默认
PDF_SPLIT_CHUNK_SIZE=250

# ----------------------------------------------------------------------------
# 数据库配置
# ----------------------------------------------------------------------------
DATABASE_PATH=/app/data/db/mineru_tianshu.db

# ----------------------------------------------------------------------------
# RustFS 对象存储配置（必须配置！）
# ----------------------------------------------------------------------------
# RustFS 服务地址（容器内部）
RUSTFS_ENDPOINT=rustfs:9000

# RustFS 访问密钥（生产环境请修改！）
RUSTFS_ACCESS_KEY=rustfsadmin
RUSTFS_SECRET_KEY=rustfsadmin

# RustFS 存储桶名称
RUSTFS_BUCKET=ts-img

# RustFS 是否使用 HTTPS
RUSTFS_SECURE=false

# RustFS 公开访问 URL（外部访问地址，必须配置！）
#
# ⚠️  重要：必须设置为外部可访问的完整 URL
# ❌ 不要使用: http://localhost:9000, http://127.0.0.1:9000, http://172.x.x.x:9000
# ✅ 使用示例:
#    - 局域网: RUSTFS_PUBLIC_URL=http://192.168.1.100:9000
#    - 公网: RUSTFS_PUBLIC_URL=http://your-domain.com:9000
#    - HTTPS: RUSTFS_PUBLIC_URL=https://files.your-domain.com
#
# 获取 Windows IP 的方法:
#   1. 在 Windows PowerShell 或 CMD 中运行: ipconfig
#   2. 找到 "IPv4 地址"，例如: 192.168.1.100
#   3. 设置: RUSTFS_PUBLIC_URL=http://192.168.1.100:9000
#
RUSTFS_PUBLIC_URL=http://192.168.100.126:9000

# RustFS 服务端口
RUSTFS_PORT=9000
RUSTFS_CONSOLE_PORT=9001

# ----------------------------------------------------------------------------
# MCP Server 配置（可选）
# ----------------------------------------------------------------------------
API_URL=http://backend:8000

# ----------------------------------------------------------------------------
# 前端配置
# ----------------------------------------------------------------------------
VITE_API_BASE_URL=http://localhost:8000

# ============================================================================
# 性能优化和配置建议
# ============================================================================
#
# 1. 设备模式选择：
#    - auto（推荐）：自动检测 GPU，有则加速，无则 CPU 降级
#    - gpu：强制使用 GPU（没有 GPU 会报错）
#    - cpu：强制使用 CPU（即使有 GPU）
#
# 2. GPU 加速要求（可选）：
#    - 最低：NVIDIA GPU 8GB 显存（如 RTX 3070, T4）
#    - 推荐：NVIDIA GPU 12-16GB 显存（如 RTX 3090, RTX 4090, V100）
#    - 最佳：NVIDIA GPU 24GB+ 显存（如 A100, A6000）
#    - CUDA 版本：需要 CUDA 12.6+ 兼容的驱动
#    - 最低 Driver 版本: 525.60.13
#    - 推荐 Driver 版本: 550.54.15+
#
# 3. CPU 和内存配置：
#    - CPU: 推荐 8核以上
#    - 内存: 推荐 32GB 以上（GPU 模式）或 16GB 以上（CPU 模式）
#
# 4. 并发处理：
#    - GPU 模式：
#      - 单 GPU：WORKER_GPUS=1
#      - 多 GPU：WORKER_GPUS=2 或更多（根据实际 GPU 数量）
#      - 可以通过 CUDA_VISIBLE_DEVICES 指定使用哪些 GPU
#    - CPU 模式：
#      - 自动使用所有可用 CPU 核心
#
# 5. 性能预期：
#    - GPU 模式比 CPU 模式快 5-10 倍
#    - GPU 模式：
#      - 10 页 PDF: 5-10 秒
#      - 100 页 PDF: 30-60 秒
#      - 1 小时音频: 1-2 分钟
#    - CPU 模式：
#      - 10 页 PDF: 30-60 秒
#      - 100 页 PDF: 5-10 分钟
#      - 1 小时音频: 10-15 分钟
#
# 6. 显存优化（GPU 模式）：
#    - 如果显存不足，可以减少 MAX_BATCH_SIZE
#    - 如果显存不足，可以减少 WORKER_GPUS
#    - 监控显存使用: nvidia-smi
#
# 7. 多 GPU 配置示例：
#    # 使用 2 个 GPU
#    WORKER_GPUS=2
#    CUDA_VISIBLE_DEVICES=0,1
#
#    # 只使用 GPU 1 和 3（跳过 0 和 2）
#    CUDA_VISIBLE_DEVICES=1,3
#    WORKER_GPUS=2
#
# 8. CPU 模式优化建议：
#    - 确保有足够的内存（至少 16GB）
#    - 使用 SSD 存储以提高 I/O 性能
#    - 减少并发任务数量
#    - 调整 WORKER_TIMEOUT 到更大值（如 600）
#
# ============================================================================
